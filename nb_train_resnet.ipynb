{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os, copy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.nets import *\n",
    "from utils.data_loader import get_train_valid_loader, get_test_loader\n",
    "from utils.utils import num_params, save_summary, read_summary, format_scientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "from fastai.torch_core import defaults\n",
    "from fastai.vision.data import ImageDataBunch\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.data import *\n",
    "from fastai.basics import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.callbacks import EarlyStoppingCallback, CSVLogger\n",
    "from utils.callbacks import ReduceLROnPlateauCallback, SaveModelCallback, MetricTracker\n",
    "from utils.tensorboard import LearnerTensorboardWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cuda = 1 # device\n",
    "k = 1\n",
    "model = gaussian_resnet20(k)\n",
    "model_code = 'gaussian_resnet20' + '(k={})'.format(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_path = Path('/root/data/cifar10')\n",
    "logs_path = Path('logs')  # relative to project directory\n",
    "model_saves_dir = Path('model_saves')\n",
    "csv_logs_dir = Path('csv_logs')\n",
    "tb_dir = Path('tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "save_model = True\n",
    "log = True\n",
    "write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_lr = 1e-1\n",
    "min_lr = 1e-4\n",
    "epochs = 150\n",
    "\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "nesterov = False\n",
    "\n",
    "bs = 128  # as used in resnet paper. Takes 1.5 MB of RAM, so not an issue\n",
    "num_workers = 4  # optimal for the given machine. sometimes gives an error if num_workers>0\n",
    "pin_memory = False  # no difference for the given machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\" + str(cuda) if torch.cuda.is_available() else \"cpu\")\n",
    "defaults.device = device\n",
    "model.to(device);\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "defaults.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_train_valid_loader(\n",
    "    data_dir=data_path, valid_size=0.1, augment=True, random_seed=42,\n",
    "    batch_size=bs, num_workers=num_workers, shuffle=True,  \n",
    "    pin_memory=pin_memory, show_sample=False)\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_dir=data_path, \n",
    "    batch_size=bs, num_workers=num_workers, shuffle=False,\n",
    "    pin_memory=pin_memory)\n",
    "\n",
    "train_epoch_len = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "callback_fns = [\n",
    "    partial(ReduceLROnPlateauCallback, monitor='valid_loss', mode='auto', patience=10, factor=0.1, min_delta=0, min_lr=min_lr),\n",
    "    partial(EarlyStoppingCallback, monitor='valid_loss', min_delta=0, patience=20),\n",
    "    partial(MetricTracker, func=accuracy, train=True, name='train_accu'),  # additionally track train accuracy\n",
    "]\n",
    "if save_model: callback_fns.append(partial(\n",
    "    SaveModelCallback, every='improvement', monitor='accuracy', \n",
    "    mode='max', name=model_code))\n",
    "if log: callback_fns.append(partial(\n",
    "    CSVLogger, append=False, filename=csv_logs_dir/model_code))\n",
    "if write: callback_fns.append(partial(\n",
    "    LearnerTensorboardWriter, base_dir=logs_path/tb_dir, name=model_code,\n",
    "    stats_iters=10*train_epoch_len, hist_iters=10*train_epoch_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bunch = ImageDataBunch(train_loader, valid_loader, test_dl=test_loader, \n",
    "                       device=device, path=data_path)\n",
    "# lr is set by fit\n",
    "sgd = partial(torch.optim.SGD, momentum=momentum, weight_decay=weight_decay, nesterov=nesterov)\n",
    "\n",
    "learn = Learner(bunch, model, loss_func=nn.CrossEntropyLoss(), opt_func=sgd, true_wd=False, wd=weight_decay, \n",
    "                metrics=[accuracy], callback_fns=callback_fns,\n",
    "                path=logs_path, model_dir=model_saves_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "learn.fit(epochs, lr=max_lr, wd=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "best_epoch, best_value = learn.save_model_callback.best_epoch, learn.save_model_callback.best\n",
    "time_to_best_epoch = learn.save_model_callback.time_to_best_epoch\n",
    "changed_lr_on_epochs = learn.reduce_lr_on_plateau_callback.changed_lr_on_epochs\n",
    "\n",
    "print(\"Best model was found at epoch {} with accuracy value {:.4f} in {:.2f} seconds.\".format(best_epoch, best_value, time_to_best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "loss_train, accu_train = learn.validate(dl=learn.data.train_dl)\n",
    "loss_valid, accu_valid = learn.validate(dl=learn.data.valid_dl)\n",
    "loss_test,  accu_test  = learn.validate(dl=learn.data.test_dl)\n",
    "# accu_train, accu_valid, accu_test = accu_train.item(), accu_valid.item(), accu_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_params, n_layers = num_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "val_dict = {'name': gaussian_resnet20.__name__+'(k={})'.format(k),\n",
    "            'accu_test': accu_test * 100,\n",
    "            'n_params': n_params,\n",
    "            'epochs': best_epoch + 1,\n",
    "            'time': time_to_best_epoch,\n",
    "            'changed_lr_on': ','.join(map(format_scientific, changed_lr_on_epochs.keys())),\n",
    "            'loss_train': loss_train, \n",
    "            'loss_valid': loss_valid, \n",
    "            'loss_test':  loss_test, \n",
    "            'accu_train': accu_train * 100, \n",
    "            'accu_valid': accu_valid * 100,\n",
    "            'accu_test (again)': accu_test * 100,\n",
    "            'other': '',\n",
    "           }\n",
    "val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "save_summary(logs_path/'models_summary.csv', val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "read_summary(logs_path/'models_summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
